{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experimentation\n",
    "\n",
    "**Problem statement:** \\\n",
    "The main goal of this project is to predict whether the tumor is Benign or Malignant. The problem is classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# preprocessing and metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# modelling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  smoothness_mean  symmetry_mean  fractal_dimension_mean  \\\n",
       "0         M          0.11840         0.2419                 0.07871   \n",
       "1         M          0.08474         0.1812                 0.05667   \n",
       "2         M          0.10960         0.2069                 0.05999   \n",
       "3         M          0.14250         0.2597                 0.09744   \n",
       "4         M          0.10030         0.1809                 0.05883   \n",
       "\n",
       "   texture_se  smoothness_se  compactness_se  concavity_se  concave points_se  \\\n",
       "0      0.9053       0.006399         0.04904       0.05373            0.01587   \n",
       "1      0.7339       0.005225         0.01308       0.01860            0.01340   \n",
       "2      0.7869       0.006150         0.04006       0.03832            0.02058   \n",
       "3      1.1560       0.009110         0.07458       0.05661            0.01867   \n",
       "4      0.7813       0.011490         0.02461       0.05688            0.01885   \n",
       "\n",
       "   symmetry_se  fractal_dimension_se  smoothness_worst  symmetry_worst  \\\n",
       "0      0.03003              0.006193            0.1622          0.4601   \n",
       "1      0.01389              0.003532            0.1238          0.2750   \n",
       "2      0.02250              0.004571            0.1444          0.3613   \n",
       "3      0.05963              0.009208            0.2098          0.6638   \n",
       "4      0.01756              0.005115            0.1374          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/data_cleaned.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data into independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 455, 114, 114)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the data into features and target\n",
    "X, y = data.drop(\"diagnosis\", axis=1), data[\"diagnosis\"]\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num features\n",
    "num_features = list(X.columns)\n",
    "\n",
    "# initialise the preprocessors\n",
    "scaler = StandardScaler()\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "\n",
    "# Create a transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num_transformer\", scaler, num_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Transform the features\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "y_train = label_enc.fit_transform(y_train)\n",
    "y_test = label_enc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_enc.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    acc = accuracy_score(true, predicted)\n",
    "    precision = precision_score(true, predicted)\n",
    "    recall = recall_score(true, predicted)\n",
    "    return (acc, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Internships\\CodersCave\\breast_cancer_prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "9 fits failed out of a total of 18.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Documents\\Internships\\CodersCave\\breast_cancer_prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Documents\\Internships\\CodersCave\\breast_cancer_prediction\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Documents\\Internships\\CodersCave\\breast_cancer_prediction\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Documents\\Internships\\CodersCave\\breast_cancer_prediction\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Documents\\Internships\\CodersCave\\breast_cancer_prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.88565993        nan 0.90546939        nan 0.89891948]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy score: 0.9231\n",
      "- Precision score: 0.9036\n",
      "- Recall Score: 0.8876\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score: 0.8947\n",
      "- Precision score: 0.8605\n",
      "- Recall Score: 0.8605\n",
      "===================================\n",
      "\n",
      "\n",
      "SVC\n",
      "Model performance for Training set\n",
      "- Accuracy score: 0.9451\n",
      "- Precision score: 0.9615\n",
      "- Recall Score: 0.8876\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score: 0.8772\n",
      "- Precision score: 0.8919\n",
      "- Recall Score: 0.7674\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy score: 0.9121\n",
      "- Precision score: 0.8957\n",
      "- Recall Score: 0.8639\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score: 0.8509\n",
      "- Precision score: 0.8250\n",
      "- Recall Score: 0.7674\n",
      "===================================\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "Model performance for Training set\n",
      "- Accuracy score: 0.7802\n",
      "- Precision score: 0.7285\n",
      "- Recall Score: 0.6509\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score: 0.7456\n",
      "- Precision score: 0.6944\n",
      "- Recall Score: 0.5814\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy score: 1.0000\n",
      "- Precision score: 1.0000\n",
      "- Recall Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score: 0.8333\n",
      "- Precision score: 0.7609\n",
      "- Recall Score: 0.8140\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy score: 1.0000\n",
      "- Precision score: 1.0000\n",
      "- Recall Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score: 0.8947\n",
      "- Precision score: 0.8780\n",
      "- Recall Score: 0.8372\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost\n",
      "Model performance for Training set\n",
      "- Accuracy score: 0.9538\n",
      "- Precision score: 0.9568\n",
      "- Recall Score: 0.9172\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score: 0.8860\n",
      "- Precision score: 0.8750\n",
      "- Recall Score: 0.8140\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy score: 1.0000\n",
      "- Precision score: 1.0000\n",
      "- Recall Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score: 0.8772\n",
      "- Precision score: 0.8372\n",
      "- Recall Score: 0.8372\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBoost\n",
      "Model performance for Training set\n",
      "- Accuracy score: 1.0000\n",
      "- Precision score: 1.0000\n",
      "- Recall Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score: 0.8772\n",
      "- Precision score: 0.8372\n",
      "- Recall Score: 0.8372\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoost\n",
      "Model performance for Training set\n",
      "- Accuracy score: 1.0000\n",
      "- Precision score: 1.0000\n",
      "- Recall Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score: 0.8596\n",
      "- Precision score: 0.8140\n",
      "- Recall Score: 0.8140\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=False)\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"penalty\": [\"l1\", \"l2\"],\n",
    "        \"C\": [0.1, 1, 10]\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"C\": [0.1, 1, 10],\n",
    "        \"kernel\": [\"linear\", \"rbf\"]\n",
    "    },\n",
    "    \"K-Neighbors Classifier\": {\n",
    "        \"n_neighbors\": [3, 5, 7],\n",
    "        \"weights\": [\"uniform\", \"distance\"]\n",
    "    },\n",
    "    \"Naive Bayes\": {},\n",
    "    \"Decision Tree\": {\n",
    "        \"max_depth\": [None, 5, 10],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [None, 5, 10],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    },\n",
    "    \"AdaBoost\": {\n",
    "        \"n_estimators\": [50, 100, 150],\n",
    "        \"learning_rate\": [0.1, 0.5, 1]\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"n_estimators\": [50, 100, 150],\n",
    "        \"learning_rate\": [0.1, 0.5, 1],\n",
    "        \"max_depth\": [3, 5, 7]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"n_estimators\": [50, 100, 150],\n",
    "        \"learning_rate\": [0.1, 0.5, 1],\n",
    "        \"max_depth\": [3, 5, 7]\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        \"iterations\": [50, 100, 150],\n",
    "        \"learning_rate\": [0.1, 0.5, 1]\n",
    "    }\n",
    "}\n",
    "\n",
    "model_list = []\n",
    "acc_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    param = hyperparameters[list(models.keys())[i]]\n",
    "\n",
    "    # hyperparameter tuning\n",
    "    gs_model = GridSearchCV(estimator=model, param_grid=param, cv=3, refit=True,\n",
    "                            n_jobs=-1, verbose=False)\n",
    "    gs_model.fit(X_train, y_train)\n",
    "\n",
    "    model.set_params(**gs_model.best_params_)\n",
    "\n",
    "    # fitting the best model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # making predictions\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "\n",
    "    train_acc, train_precision, train_recall = evaluate_model(\n",
    "        y_train, train_preds)\n",
    "    test_acc, test_precision, test_recall = evaluate_model(y_test, test_preds)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy score: {:.4f}\".format(train_acc))\n",
    "    print(\"- Precision score: {:.4f}\".format(train_precision))\n",
    "    print(\"- Recall Score: {:.4f}\".format(train_recall))\n",
    "\n",
    "    print('----------------------------------')\n",
    "\n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Accuracy score: {:.4f}\".format(test_acc))\n",
    "    print(\"- Precision score: {:.4f}\".format(test_precision))\n",
    "    print(\"- Recall Score: {:.4f}\".format(test_recall))\n",
    "    acc_list.append(test_acc)\n",
    "\n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.885965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.877193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.877193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.877193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.859649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>0.850877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.745614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Name  Accuracy Score\n",
       "0     Logistic Regression        0.894737\n",
       "5           Random Forest        0.894737\n",
       "6                AdaBoost        0.885965\n",
       "1                     SVC        0.877193\n",
       "7       Gradient Boosting        0.877193\n",
       "8                 XGBoost        0.877193\n",
       "9                CatBoost        0.859649\n",
       "2  K-Neighbors Classifier        0.850877\n",
       "4           Decision Tree        0.833333\n",
       "3             Naive Bayes        0.745614"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(model_list, acc_list)), columns=[\n",
    "             'Model Name', 'Accuracy Score']).sort_values(by=[\"Accuracy Score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression and Random Forest are best performing models. So let's select the Random Forest model as the best model as it can learn complex relations among the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
